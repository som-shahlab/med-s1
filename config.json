{
    "model_choices": {
        "base": "qwq:32B",
        "huatuo": "huatuo:8b",
        "nemotron": "nemotron:8b",
        "specialty_labeler": "gemini-2.0-flash",
        "base_judge": "gemini-2.0-flash",
        "curation": "gemini-2.0-flash"
    },
    "models": {
        "qwen2.5:7b": {
            "hf_path": "Qwen/Qwen2.5-7B-Instruct",
            "max_length": 128000
        },
        "llama3.1:8b": {
            "hf_path": "meta-llama/Llama-3.1-8B-Instruct",
            "max_length": 128000
        },
        "qwq:32B": {
            "hf_path": "Qwen/QwQ-32B",
            "max_length": 128000
        },
        "huatuo:8b": {
            "hf_path": "FreedomIntelligence/HuatuoGPT-o1-8B",
            "max_length": 128000
        },
        "nemotron:8b": {
            "hf_path": "nvidia/Llama-3.1-Nemotron-Nano-8B-v1",
            "max_length": 128000,
            "system_prompt": "detailed thinking {thinking}",
            "chat_template": {
                "messages": [
                    {"role": "system", "content": "{system_prompt}"},
                    {"role": "user", "content": "{question}"},
                    {"role": "assistant", "content": "<think>{thinking}</think>{answer}"}
                ]
            }
        },
        "gpt4o-mini": {
            "max_length": 128000,
            "pricing": {
                "input": 0.15,
                "output": 0.6
            }
        },
        "gemini-2.0-flash": {
            "max_length": 128000,
            "base_url": "https://generativelanguage.googleapis.com/v1beta/openai/",
            "pricing": {
                "input": 0.1,
                "output": 0.4,
                "rpm": 2000
            }
        }
    },
    "train_datasets": {
        "huatuo-sft": {
            "hf_path": "FreedomIntelligence/medical-o1-reasoning-SFT",
            "hf_config": "en",
            "hf_split": "train",
            "description": "HuatuoGPT SFT dataset with ~25k examples"
        },
        "s1-gemini-raw" : {
            "hf_path": "qfq/geminiall_nona",
            "description": "S1 raw dataset (post-dropping NAs) with ~54k examples (using Gemini reasoning traces); See: https://github.com/simplescaling/s1/blob/main/data/filter.ipynb"
        },
        "nejmcr": {
            "file_path": "/share/pi/nigam/mwornow/med-s1/data_collection/nejm_case_reports/outputs/4_create_dataset/",
            "description": "NEJM Case Reports dataset with ~1.7k examples"
        }
    },
    "eval_datasets": {
        "huatuo-eval": {
            "file_path": "${MED_S1_DIR}/eval/data/eval_data.json",
            "description": "HuatuoGPT evaluation dataset with ~10k examples"
        },
        "gpqa-diamond" : {
            "hf_path": "Idavidrein/gpqa",
            "description": "Gpqa diamond eval dataset",
            "hf_split": "train",
            "hf_config": "gpqa_diamond"
        },
        "math500" : {
            "hf_path": "simplescaling/openaimath",
            "description": "Math500 eval dataset",
            "hf_split": "test"
        },
        "aime24_nofigures" : {
            "hf_path": "simplescaling/aime24_nofigures",
            "description": "AIME 2024 eval dataset (no figures)",
            "hf_split": "train"
        },
        "aime24_figures" : {
            "hf_path": "simplescaling/aime24_figures",
            "description": "AIME 2024 eval dataset (with figures)",
            "hf_split": "train"
        }
    },
    "curation": {
        "llama_batch_size": 1024,
        "gemini_batch_size": 512,
        "initial_sample": 0
    }
}